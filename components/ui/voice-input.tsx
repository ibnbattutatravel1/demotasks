"use client"

import { Mic, MicOff, Loader2 } from "lucide-react"
import { useState, useEffect, useRef } from "react"
import { Button } from "./button"
import { useToast } from "./use-toast"

interface VoiceInputProps {
  onTranscript: (text: string) => void
  className?: string
}

export function VoiceInput({ onTranscript, className }: VoiceInputProps) {
  const [isListening, setIsListening] = useState(false)
  const [isSupported, setIsSupported] = useState(false)
  const recognitionRef = useRef<any>(null)
  const { toast } = useToast()

  useEffect(() => {
    // Check if browser supports Web Speech API
    if (typeof window !== 'undefined') {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
      setIsSupported(!!SpeechRecognition)

      if (SpeechRecognition) {
        const recognition = new SpeechRecognition()
        recognition.continuous = false
        recognition.interimResults = false
        recognition.lang = 'ar-SA' // Arabic (Saudi Arabia) - ÙŠÙ…ÙƒÙ† ØªØºÙŠÙŠØ±Ù‡

        recognition.onresult = (event: any) => {
          const transcript = event.results[0][0].transcript
          onTranscript(transcript)
          setIsListening(false)
        }

        recognition.onerror = (event: any) => {
          console.error('Speech recognition error:', event.error)
          setIsListening(false)
          
          let errorMessage = 'Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª'
          switch (event.error) {
            case 'no-speech':
              errorMessage = 'Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù ØµÙˆØª. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.'
              break
            case 'audio-capture':
              errorMessage = 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†.'
              break
            case 'not-allowed':
              errorMessage = 'ØªÙ… Ø±ÙØ¶ Ø¥Ø°Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†.'
              break
            default:
              errorMessage = `Ø®Ø·Ø£: ${event.error}`
          }
          
          toast({
            title: "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠ",
            description: errorMessage,
            variant: "destructive",
          })
        }

        recognition.onend = () => {
          setIsListening(false)
        }

        recognitionRef.current = recognition
      }
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop()
      }
    }
  }, [onTranscript, toast])

  const toggleListening = () => {
    if (!recognitionRef.current) return

    if (isListening) {
      recognitionRef.current.stop()
      setIsListening(false)
    } else {
      try {
        recognitionRef.current.start()
        setIsListening(true)
        toast({
          title: "ğŸ¤ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹...",
          description: "ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†ØŒ Ø³ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„ ÙƒÙ„Ø§Ù…Ùƒ Ø¥Ù„Ù‰ Ù†Øµ",
        })
      } catch (error) {
        console.error('Error starting recognition:', error)
        toast({
          title: "Ø®Ø·Ø£",
          description: "ÙØ´Ù„ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª",
          variant: "destructive",
        })
      }
    }
  }

  if (!isSupported) {
    return null // Don't show button if not supported
  }

  return (
    <Button
      type="button"
      variant="ghost"
      size="sm"
      onClick={toggleListening}
      className={`${className} ${isListening ? 'text-red-500 hover:text-red-600 animate-pulse' : 'text-slate-500 hover:text-slate-700'}`}
      title={isListening ? "Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„" : "Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ"}
    >
      {isListening ? <MicOff className="w-4 h-4" /> : <Mic className="w-4 h-4" />}
    </Button>
  )
}
